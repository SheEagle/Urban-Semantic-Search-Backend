# app/services/search_service.py
import io
from typing import Optional, List

import numpy as np
from PIL import Image

from backend.app.core.config import settings
from backend.app.schema.search import SearchResultItem, SearchFilters
from backend.app.utils.global_state import GlobalState

from qdrant_client import models


class SearchService:
    def __init__(self):
        self.collection_name = settings.COLLECTION_NAME
        self.MAP_COLLECTION = settings.MAP_COLLECTION
        self.DOC_COLLECTION = settings.DOC_COLLECTION

    def _normalize_scores(self, results: List[SearchResultItem]) -> List[SearchResultItem]:
        """
        å¯¹æœç´¢ç»“æœçš„åˆ†æ•°è¿›è¡Œ Z-Score å½’ä¸€åŒ– (Standardization)ã€‚
        å°†ä¸åŒåˆ†å¸ƒçš„åˆ†æ•°æ˜ å°„åˆ°å‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º1çš„åˆ†å¸ƒä¸Šã€‚
        """
        if not results:
            return results

        # 1. æå–æ‰€æœ‰åˆ†æ•°
        scores = [r.score for r in results]

        # 2. è®¡ç®—ç»Ÿè®¡é‡
        mean = np.mean(scores)
        std = np.std(scores)

        # 3. é˜²å¾¡æ€§å¤„ç†ï¼šå¦‚æœæ ‡å‡†å·®ä¸º0ï¼ˆä¾‹å¦‚åªæœ‰ä¸€ä¸ªç»“æœï¼Œæˆ–æ‰€æœ‰åˆ†æ•°ç›¸åŒï¼‰
        if std == 0:
            # è¿™ç§æƒ…å†µä¸‹æ— æ³•è¿›è¡Œ Z-Scoreï¼Œå¯ä»¥é€‰æ‹©ä¸å¤„ç†ï¼Œæˆ–è€…å½’ä¸€åŒ–ä¸º 0
            # è¿™é‡Œé€‰æ‹©ä¿æŒåŸæ ·ï¼Œæˆ–è€…ä½ å¯ä»¥æ‰‹åŠ¨è®¾ä¸º 1.0 (å¦‚æœåˆ†æ•°éƒ½å¾ˆé«˜)
            return results

        # 4. æ‰§è¡Œå½’ä¸€åŒ–
        for r in results:
            # æ–°åˆ†æ•° = (æ—§åˆ†æ•° - å‡å€¼) / æ ‡å‡†å·®
            # æ³¨æ„ï¼šè¿™æ ·å¤„ç†åï¼Œåˆ†æ•°ä¼šæœ‰æ­£æœ‰è´Ÿ
            r.score = (r.score - mean) / std

        return results

    def _build_qdrant_filters(self, filters: SearchFilters) -> Optional[models.Filter]:
        """
        è¾…åŠ©å‡½æ•°ï¼šå°† Pydantic è¿‡æ»¤å™¨è½¬æ¢ä¸º Qdrant Filter å¯¹è±¡
        """
        if not filters:
            return None

        conditions = []

        # 1. å¹´ä»½èŒƒå›´è¿‡æ»¤ (Payload ä¸­å¿…é¡»æœ‰ 'year' å­—æ®µ)
        if filters.year_start is not None:
            conditions.append(
                models.FieldCondition(
                    key="year",
                    range=models.Range(gte=filters.year_start)
                )
            )
        if filters.year_end is not None:
            conditions.append(
                models.FieldCondition(
                    key="year",
                    range=models.Range(lte=filters.year_end)
                )
            )

        # 2. ç‰¹å®šåœ°å›¾æ¥æºè¿‡æ»¤ (Payload ä¸­å¿…é¡»æœ‰ 'source_image' å­—æ®µ)
        if filters.map_source:
            conditions.append(
                models.FieldCondition(
                    key="source_image",
                    match=models.MatchValue(value=filters.map_source)
                )
            )

        # 3. åæ ‡èŒƒå›´è¿‡æ»¤ (Payload ä¸­å¿…é¡»æœ‰ 'location' Geo å­—æ®µ)
        # å‡è®¾ bbox æ ¼å¼ä¸º [min_lon, min_lat, max_lon, max_lat]
        if filters.geo_bbox and len(filters.geo_bbox) == 4:
            conditions.append(
                models.FieldCondition(
                    key="location",  # Qdrant ä¸­çš„ Payload å­—æ®µå
                    geo_bounding_box=models.GeoBoundingBox(
                        bottom_right=models.GeoPoint(
                            lon=filters.geo_bbox[2],
                            lat=filters.geo_bbox[1]
                        ),
                        top_left=models.GeoPoint(
                            lon=filters.geo_bbox[0],
                            lat=filters.geo_bbox[3]
                        )
                    )
                )
            )

        if not conditions:
            return None

        return models.Filter(must=conditions)

        # ä¿®æ”¹é€šç”¨çš„æ‰§è¡Œæ–¹æ³•ï¼Œæ¥æ”¶ query_filter

    # --- æ ¸å¿ƒä¿®æ”¹ï¼šæ–‡æœæ–‡é€»è¾‘ ---
    def _search_documents(self, query: str, limit: int, threshold: float, q_filter: models.Filter) -> List[
        SearchResultItem]:
        """
        ä½¿ç”¨ MiniLM æ¨¡å‹æœç´¢ venice_docs é›†åˆ (æ–‡æœæ–‡)
        """
        client = GlobalState.get_db()
        text_model = GlobalState.get_text_model()  # ğŸ”¥ è·å– MiniLM

        # 1. ç”Ÿæˆè¯­ä¹‰å‘é‡
        vector = text_model.encode(query).tolist()

        # 2. æœç´¢ venice_docs
        hits = client.query_points(
            collection_name=self.DOC_COLLECTION,
            # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šquery åªä¼ å‘é‡å€¼
            query=vector,

            # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šç”¨ using æŒ‡å®šå‘é‡åç§°
            using="text_vector",
            query_filter=q_filter,
            limit=limit,
            with_payload=True
        )

        if hasattr(hits, 'points'):
            hits = hits.points
        elif isinstance(hits, tuple) and hits[0] == 'points':
            hits = hits[1]

        results = []

        for i, hit in enumerate(hits):
            if isinstance(hit, tuple): continue
            if not hasattr(hit, 'score'): continue
            if hit.score < threshold: continue

            payload = hit.payload or {}
            loc = payload.get('location', {})

            results.append(SearchResultItem(
                id=str(hit.id),
                score=hit.score,
                lat=loc.get('lat', 0.0),
                lng=loc.get('lon', 0.0),
                image_source=payload.get('source_dataset', 'Document'),
                content=payload.get('content', '')[:200] + "...",  # æˆªå–æ‘˜è¦
                fullData=payload,
                type="document",  # ğŸ”¥ æ ‡è®°ä¸ºæ–‡æ¡£
                pixel_coords=None
            ))
        return results

        # --- æ ¸å¿ƒä¿®æ”¹ï¼šæ–‡æœå›¾é€»è¾‘ (åŸæœ‰çš„é€»è¾‘å¾®è°ƒ) ---

    def _search_maps_by_text(self, query: str, limit: int, threshold: float, q_filter: models.Filter) -> List[
        SearchResultItem]:
        """
        ä½¿ç”¨ PE æ¨¡å‹æœç´¢ venice_maps é›†åˆ (æ–‡æœå›¾)
        """
        client = GlobalState.get_db()
        pe_model = GlobalState.get_pe_model()  # ğŸ”¥ è·å– PE/CLIP

        # 1. ç¿»è¯‘ (å¯é€‰ï¼Œå»ºè®®åŠ ä¸Š)
        # try:
        #     query = GoogleTranslator(source='auto', target='en').translate(query)
        # except: pass

        # 2. ç”Ÿæˆè§†è§‰å¯¹é½å‘é‡
        # extract_text_features è¿”å› numpy array
        vector_np = pe_model.extract_text_features(query)
        # å¤„ç†å¯èƒ½çš„ç»´åº¦é—®é¢˜ (1, 512) -> [512]
        if hasattr(vector_np, 'tolist'):
            vector_list = vector_np.tolist()
        else:
            vector_list = vector_np

        if isinstance(vector_list[0], list):
            vector_list = vector_list[0]

        # 3. æœç´¢ venice_maps
        hits = client.query_points(
            collection_name=self.MAP_COLLECTION,
            query=vector_list,  # ğŸ”¥ æŒ‡å®š pe_vector
            query_filter=q_filter,
            limit=limit,
            with_payload=True
        )

        if hasattr(hits, 'points'):
            hits = hits.points
        elif isinstance(hits, tuple) and hits[0] == 'points':
            hits = hits[1]

        results = []

        for i, hit in enumerate(hits):
            if isinstance(hit, tuple): continue
            if not hasattr(hit, 'score'): continue
            if hit.score < threshold: continue

            payload = hit.payload or {}
            loc = payload.get('location', {})

            results.append(SearchResultItem(
                id=str(hit.id),
                score=hit.score,
                lat=loc.get('lat', 0.0),
                lng=loc.get('lon', 0.0),
                pixel_coords=payload.get('pixel_coords'),
                image_source=payload.get('source_image'),
                content=f"Map Fragment ({payload.get('year', '')})",
                fullData=payload,
                type="map_tile"  # ğŸ”¥ æ ‡è®°ä¸ºåœ°å›¾åˆ‡ç‰‡
            ))
        return results

    # --- ä¸»å…¥å£ï¼šæ–‡æœ¬æœç´¢ ---
    def search_text(self, query: str, limit: int, threshold: float, filters: Optional[SearchFilters] = None) -> List[
        SearchResultItem]:
        q_filter = self._build_qdrant_filters(filters)

        # å®šä¹‰ä¸¤ä¸ªæ¨¡å‹å„è‡ªçš„â€œåŠæ ¼çº¿â€
        # ç»éªŒå€¼ï¼šMiniLM ä½äº 0.4 é€šå¸¸æ˜¯ä¸ç›¸å…³çš„
        DOC_MIN_SCORE = 0.35
        # ç»éªŒå€¼ï¼šCLIP/PE ä½äº 0.15 é€šå¸¸æ˜¯éšæœºå™ªå£°
        MAP_MIN_SCORE = 0.18
        Z_SCORE_THRESHOLD = 0  # å‰”é™¤ä½äºå¹³å‡æ°´å¹³åŠä¸ªæ ‡å‡†å·®çš„ç»“æœ

        doc_results = []
        map_results = []

        # 1. æœæ–‡æ¡£
        try:
            # å…ˆæ‹¿å›æ¥å¤šä¸€ç‚¹
            raw_docs = self._search_documents(query, limit * 2, 0, q_filter)
            # ğŸ›¡ï¸ ç¬¬ä¸€é“é˜²çº¿ï¼šç»å¯¹é˜ˆå€¼è¿‡æ»¤
            doc_results = [r for r in raw_docs if r.score > DOC_MIN_SCORE]
        except Exception as e:
            print(f"âš ï¸ Doc search failed: {e}")

        # 2. æœåœ°å›¾
        try:
            raw_maps = self._search_maps_by_text(query, limit * 2, 0, q_filter)
            # ğŸ›¡ï¸ ç¬¬ä¸€é“é˜²çº¿ï¼šç»å¯¹é˜ˆå€¼è¿‡æ»¤
            map_results = [r for r in raw_maps if r.score > MAP_MIN_SCORE]
        except Exception as e:
            print(f"âš ï¸ Map search failed: {e}")

        # --- å¦‚æœæŸä¸€æ–¹è¢«è¿‡æ»¤å®Œäº†ï¼Œå°±åªå‰©å¦ä¸€æ–¹ï¼Œé¿å…äº†å¼ºè¡Œæ‹‰é«˜ ---

        # 3. Z-Score å½’ä¸€åŒ– (ç›¸å¯¹æ’åº)
        if doc_results:
            doc_results = self._normalize_scores(doc_results)

        if map_results:
            map_results = self._normalize_scores(map_results)

        # 4. åˆå¹¶ä¸æ’åº
        all_results = doc_results + map_results
        final_results = [r for r in all_results if r.score > Z_SCORE_THRESHOLD]

        # --- E. æ’åºä¸æˆªæ–­ ---
        final_results.sort(key=lambda x: x.score, reverse=True)
        return final_results[:2 * limit]

    # def search_text(self, query: str, limit: int, threshold: float, filters: Optional[SearchFilters] = None) -> \
    #         List[SearchResultItem]:
    #     """
    #     èšåˆæœç´¢ï¼šåŒæ—¶æœæ–‡æ¡£å’Œåœ°å›¾
    #     """
    #     q_filter = self._build_qdrant_filters(filters)
    #
    #     results = []
    #
    #     # 1. æœæ–‡æ¡£ (æ–‡æœæ–‡)
    #     try:
    #         doc_results = self._search_documents(query, limit, threshold, q_filter)
    #         results.extend(doc_results)
    #     except Exception as e:
    #         print(f"âš ï¸ Doc search failed: {e}")
    #
    #     # 2. æœåœ°å›¾ (æ–‡æœå›¾)
    #     try:
    #         map_results = self._search_maps_by_text(query, limit, threshold, q_filter)
    #         results.extend(map_results)
    #     except Exception as e:
    #         print(f"âš ï¸ Map search failed: {e}")
    #
    #     # 3. ç»Ÿä¸€æ’åº (æŒ‰åˆ†æ•°ä»é«˜åˆ°ä½)
    #     results.sort(key=lambda x: x.score, reverse=True)
    #
    #     # 4. æˆªå– Top K
    #     return results[:2 * limit]

    def _execute_qdrant_search(self, vector_list: list, limit: int, threshold: float,
                               query_filter: models.Filter = None):
        client = GlobalState.get_db()

        hits = client.query_points(
            collection_name=self.collection_name,
            query=vector_list,
            limit=limit,
            query_filter=query_filter
        )

        if hasattr(hits, 'points'):
            hits = hits.points
        elif isinstance(hits, tuple) and hits[0] == 'points':
            hits = hits[1]

        return self._process_hits(hits, threshold)

    def _process_hits(self, hits: list, threshold: float):
        results = []
        # 6. ç»“æœå°è£… (é€»è¾‘åŒ search_textï¼Œå¯ä»¥æŠ½å–æˆä¸€ä¸ªç§æœ‰æ–¹æ³• _hits_to_results)
        for i, hit in enumerate(hits):
            if isinstance(hit, tuple): continue
            if not hasattr(hit, 'score'): continue
            if hit.score < threshold: continue

            payload = hit.payload or {}
            loc = payload.get('location', {})

            item = SearchResultItem(
                id=str(hit.id),
                score=hit.score,
                lat=loc.get('lat', 0.0),
                lng=loc.get('lon', 0.0),
                pixel_coords=payload.get('pixel_coords', [0, 0]),
                image_source=payload.get('source_image'),
                geo_polygon=payload.get('geo_detail')
            )
            results.append(item)

        return results

    def search_image(self, image_data: bytes, limit: int, threshold: float) -> list[SearchResultItem]:
        # 1. è·å–å•ä¾‹
        client = GlobalState.get_db()
        model = GlobalState.get_pe_model()

        # 2. å›¾ç‰‡é¢„å¤„ç†
        try:
            image = Image.open(io.BytesIO(image_data))
        except Exception as e:
            raise ValueError(f"Invalid image file: {e}")

        # 3. æå–ç‰¹å¾
        # model.extract_image_features è¿”å›çš„æ˜¯ shape ä¸º (1, ç»´åº¦) çš„ numpy æ•°ç»„
        feature_array = model.extract_image_features([image])

        # 4. è½¬æ¢æ ¼å¼
        # å–å‡ºç¬¬0ä¸ªå…ƒç´ ï¼ˆå› ä¸ºæˆ‘ä»¬åªä¼ äº†1å¼ å›¾ï¼‰ï¼Œå¹¶è½¬ä¸º python list
        vector_list = feature_array[0].tolist()

        # 5. Qdrant æœç´¢ (é€»è¾‘å®Œå…¨å¤ç”¨ text searchï¼Œå› ä¸ºéƒ½æ˜¯å‘é‡æœå‘é‡)
        print(f"ğŸ–¼ï¸ [Service] Searching Image in '{self.collection_name}'...")
        hits = client.query_points(
            collection_name=self.collection_name,
            query=vector_list,
            limit=limit
        )

        if hasattr(hits, 'points'):
            hits = hits.points
        elif isinstance(hits, tuple) and hits[0] == 'points':
            hits = hits[1]

        results = []

        # 6. ç»“æœå°è£… (é€»è¾‘åŒ search_textï¼Œå¯ä»¥æŠ½å–æˆä¸€ä¸ªç§æœ‰æ–¹æ³• _hits_to_results)
        for i, hit in enumerate(hits):
            if isinstance(hit, tuple): continue
            if not hasattr(hit, 'score'): continue
            if hit.score < threshold: continue

            payload = hit.payload or {}
            loc = payload.get('location', {})

            item = SearchResultItem(
                id=str(hit.id),
                score=hit.score,
                lat=loc.get('lat', 0.0),
                lng=loc.get('lon', 0.0),
                pixel_coords=payload.get('pixel_coords', [0, 0]),
                image_source=payload.get('source_image'),
                geo_polygon=payload.get('geo_detail')
            )
            results.append(item)

        return results

    # def search_text(self, query: str, limit: int, threshold: float) -> list[SearchResultItem]:
    #     # 1. è·å–å•ä¾‹
    #     client = GlobalState.get_db()
    #     model = GlobalState.get_model()
    #
    #     # 2. æ–‡æœ¬ç¼–ç  (è°ƒç”¨ utils)
    #     # æ³¨æ„ï¼šè¿™é‡Œä¼šè¿”å› (1, dim) çš„ numpy array
    #     raw_vector = model.extract_text_features(query)
    #
    #     # 3. æ ¼å¼è½¬æ¢ (Numpy -> List)
    #     if hasattr(raw_vector, 'flatten'):
    #         vector_list = raw_vector.flatten().tolist()
    #     elif isinstance(raw_vector, list):
    #         vector_list = raw_vector
    #     else:
    #         vector_list = raw_vector.tolist()
    #
    #     # 4. Qdrant æœç´¢
    #     print(f"ğŸ” [Service] Searching in '{self.collection_name}'...")
    #     hits = client.query_points(
    #         collection_name=self.collection_name,
    #         query=vector_list,
    #         limit=limit
    #     )
    #
    #     if hasattr(hits, 'points'):
    #         hits = hits.points
    #     elif isinstance(hits, tuple) and hits[0] == 'points':
    #         # åº”å¯¹æç«¯æƒ…å†µï¼Œå¦‚æœå®ƒæœ¬èº«å°±æ˜¯ä¸ªå…ƒç»„
    #         hits = hits[1]
    #
    #         # è°ƒè¯•æ‰“å°ï¼Œç¡®ä¿ç°åœ¨ hits æ˜¯ä¸ªåˆ—è¡¨
    #     # if isinstance(hits, list) and len(hits) > 0:
    #
    #     results = []
    #
    #     # 3. éå†ç»“æœ
    #     for i, hit in enumerate(hits):
    #         # é˜²å¾¡æ€§ç¼–ç¨‹ï¼šå†æ¬¡æ£€æŸ¥ hit æ˜¯å¦ä¸º tuple (åº”å¯¹ä¸€äº›å¥‡æ€ªçš„è¿­ä»£å™¨è¡Œä¸º)
    #         if isinstance(hit, tuple):
    #             # å¦‚æœæ­¤æ—¶ hit è¿˜æ˜¯å…ƒç»„ ('points', [...])ï¼Œè¯´æ˜æ‹†ç®±æ²¡æ‹†å¹²å‡€æˆ–è€…ç»“æ„åµŒå¥—äº†
    #             # è¿™ç§æƒ…å†µä¸‹é€šå¸¸è·³è¿‡æˆ–è€…å°è¯•å–å€¼ï¼Œè¿™é‡Œæˆ‘ä»¬åšä¸ªæ—¥å¿—
    #             print(f"âš ï¸ è·³è¿‡å¼‚å¸¸æ•°æ®ç»“æ„ (index {i}): {hit}")
    #             continue
    #
    #         # æ­£å¸¸é€»è¾‘ï¼šhit åº”è¯¥æ˜¯ ScoredPoint å¯¹è±¡
    #         if not hasattr(hit, 'score'):
    #             print(f"âš ï¸ è·³è¿‡æ— æ•ˆç‚¹ (index {i}), æ—  score å±æ€§")
    #             continue
    #
    #         if hit.score < threshold:
    #             continue
    #
    #         payload = hit.payload or {}
    #         loc = payload.get('location', {})
    #
    #         item = SearchResultItem(
    #             id=str(hit.id),
    #             score=hit.score,
    #             lat=loc.get('lat', 0.0),
    #             lng=loc.get('lon', 0.0),
    #             pixel_coords=payload.get('pixel_coords', [0, 0]),
    #             image_source=payload.get('source_image'),
    #             geo_polygon=payload.get('geo_detail')
    #         )
    #         results.append(item)
    #
    #     return results

    # def search_text(self, query: str, limit: int, threshold: float, filters: SearchFilters = None):
    #     model = GlobalState.get_model()
    #     vector_list = model.extract_text_features(query)[0].tolist()
    #
    #     # æ„å»ºè¿‡æ»¤å™¨
    #     q_filter = self._build_qdrant_filters(filters)
    #
    #     return self._execute_qdrant_search(vector_list, limit, threshold, query_filter=q_filter)

    def get_heatmap_points(self, query: str = None, year_start: int = None, year_end: int = None, limit: int = 10000):
        client = GlobalState.get_db()
        model = GlobalState.get_model()

        # 1. æ„å»ºè¿‡æ»¤å™¨ (æ—¶é—´/åœ°å›¾æºç­‰)
        # å¤ç”¨ä½ ä¹‹å‰å†™å¥½çš„ _build_qdrant_filters
        filters_obj = SearchFilters(year_start=year_start, year_end=year_end)
        q_filter = self._build_qdrant_filters(filters_obj)

        heatmap_data = []

        # --- åˆ†æ”¯ A: æœç´¢æ¨¡å¼ (æœ‰å…³é”®è¯) ---
        if query:
            # 1. æ–‡æœ¬è½¬å‘é‡
            vector = model.extract_text_features(query)[0].tolist()

            # 2. å‘é‡æœç´¢
            hits = client.search(
                collection_name=self.collection_name,
                query_vector=vector,
                query_filter=q_filter,
                limit=limit,  # è¿™é‡Œ limit å¯ä»¥å¼€å¤§ä¸€ç‚¹
                with_payload=['location'],  # ğŸ”¥ å…³é”®ï¼šåªå– locationï¼Œä¸è¦å…¶ä»–å¤§å­—æ®µ
                with_vectors=False
            )

            for hit in hits:
                loc = hit.payload.get('location', {})
                if 'lat' in loc and 'lon' in loc:
                    heatmap_data.append({
                        "lat": loc['lat'],
                        "lng": loc['lon'],
                        "score": hit.score  # ç”¨ç›¸ä¼¼åº¦ä½œä¸ºçƒ­åŠ›æƒé‡
                    })

        # --- åˆ†æ”¯ B: å…¨é‡/æµè§ˆæ¨¡å¼ (æ— å…³é”®è¯) ---
        else:
            # ä½¿ç”¨ Scroll æ¥å£éå†æ•°æ®
            # Qdrant çš„ scroll ä¸€æ¬¡æœ€å¤šè¿”å›å‡ åƒæ¡ï¼Œå¦‚æœæ•°æ®é‡æå¤§éœ€è¦å¾ªç¯ scroll
            # è¿™é‡Œæ¼”ç¤ºç®€å•çš„ä¸€æ¬¡æ€§ scroll
            response = client.scroll(
                collection_name=self.collection_name,
                scroll_filter=q_filter,
                limit=limit,
                with_payload=['location'],  # ğŸ”¥ å…³é”®ï¼šåªå– location
                with_vectors=False
            )
            points = response[0]  # response æ˜¯ (points, offset)

            for point in points:
                loc = point.payload.get('location', {})
                if 'lat' in loc and 'lon' in loc:
                    heatmap_data.append({
                        "lat": loc['lat'],
                        "lng": loc['lon'],
                        "score": 1.0  # å…¨é‡æ¨¡å¼ä¸‹ï¼Œå¯†åº¦å³çƒ­åº¦ï¼Œæƒé‡è®¾ä¸º 1
                    })

        return heatmap_data


# å¯¼å‡ºå®ä¾‹
search_service = SearchService()
